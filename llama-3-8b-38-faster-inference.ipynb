{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3008e3f0",
   "metadata": {
    "papermill": {
     "duration": 0.01066,
     "end_time": "2024-07-04T14:52:14.234623",
     "exception": false,
     "start_time": "2024-07-04T14:52:14.223963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd95f68d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:52:14.258045Z",
     "iopub.status.busy": "2024-07-04T14:52:14.257773Z",
     "iopub.status.idle": "2024-07-04T14:53:12.094861Z",
     "shell.execute_reply": "2024-07-04T14:53:12.093536Z"
    },
    "papermill": {
     "duration": 57.851893,
     "end_time": "2024-07-04T14:53:12.097425",
     "exception": false,
     "start_time": "2024-07-04T14:52:14.245532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28b0925",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:53:12.121517Z",
     "iopub.status.busy": "2024-07-04T14:53:12.121196Z",
     "iopub.status.idle": "2024-07-04T14:53:31.134241Z",
     "shell.execute_reply": "2024-07-04T14:53:31.133383Z"
    },
    "papermill": {
     "duration": 19.027766,
     "end_time": "2024-07-04T14:53:31.136669",
     "exception": false,
     "start_time": "2024-07-04T14:53:12.108903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 14:53:22.789441: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-04 14:53:22.789626: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-04 14:53:22.908047: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a83ce52",
   "metadata": {
    "papermill": {
     "duration": 0.013169,
     "end_time": "2024-07-04T14:53:31.162939",
     "exception": false,
     "start_time": "2024-07-04T14:53:31.149770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "According to the pytorch [documentation](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html?highlight=scaled_dot_product#torch.nn.functional.scaled_dot_product_attention), `scaled_dot_product_attention` automatically select the most optimal implementation from:\n",
    "1. Flash Attention\n",
    "2. Memory Efficient Attention\n",
    "3. A PyTorch (naive) implementation\n",
    "\n",
    "By default, all of those are enabled but we can also manually enable/disable certain backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1f81a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:53:31.192030Z",
     "iopub.status.busy": "2024-07-04T14:53:31.191162Z",
     "iopub.status.idle": "2024-07-04T14:53:31.198027Z",
     "shell.execute_reply": "2024-07-04T14:53:31.196866Z"
    },
    "papermill": {
     "duration": 0.024047,
     "end_time": "2024-07-04T14:53:31.200452",
     "exception": false,
     "start_time": "2024-07-04T14:53:31.176405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert torch.cuda.device_count() == 2, \"Sorry - multi-GPU required!\"\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
    "torch.backends.cuda.enable_flash_sdp(True)  # Doesn't have any effect as Flash Attention does not support T4/P100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d39edad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:53:31.230404Z",
     "iopub.status.busy": "2024-07-04T14:53:31.229430Z",
     "iopub.status.idle": "2024-07-04T14:53:31.236185Z",
     "shell.execute_reply": "2024-07-04T14:53:31.235096Z"
    },
    "papermill": {
     "duration": 0.023545,
     "end_time": "2024-07-04T14:53:31.238478",
     "exception": false,
     "start_time": "2024-07-04T14:53:31.214933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    model_name = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n",
    "    weights_path = '/kaggle/input/lmsys-model/model'\n",
    "    max_length = 2048\n",
    "    batch_size = 4\n",
    "    device = torch.device(\"cuda\")    \n",
    "    tta = False  # test time augmentation. <prompt>-<model-b's response>-<model-a's response>\n",
    "    spread_max_length = False  # whether to apply max_length//3 on each input or max_length on the concatenated input\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db00c6",
   "metadata": {
    "papermill": {
     "duration": 0.012892,
     "end_time": "2024-07-04T14:53:31.264867",
     "exception": false,
     "start_time": "2024-07-04T14:53:31.251975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50368e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:53:31.292741Z",
     "iopub.status.busy": "2024-07-04T14:53:31.291973Z",
     "iopub.status.idle": "2024-07-04T14:53:31.326467Z",
     "shell.execute_reply": "2024-07-04T14:53:31.325387Z"
    },
    "papermill": {
     "duration": 0.050493,
     "end_time": "2024-07-04T14:53:31.328913",
     "exception": false,
     "start_time": "2024-07-04T14:53:31.278420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>I have three oranges today, I ate an orange ye...</td>\n",
       "      <td>You have two oranges today.</td>\n",
       "      <td>You still have three oranges. Eating an orange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>You are a mediator in a heated political debat...</td>\n",
       "      <td>Thank you for sharing the details of the situa...</td>\n",
       "      <td>Mr Reddy and Ms Blue both have valid points in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>How to initialize the classification head when...</td>\n",
       "      <td>When you want to initialize the classification...</td>\n",
       "      <td>To initialize the classification head when per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt  \\\n",
       "0   136060  I have three oranges today, I ate an orange ye...   \n",
       "1   211333  You are a mediator in a heated political debat...   \n",
       "2  1233961  How to initialize the classification head when...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                        You have two oranges today.   \n",
       "1  Thank you for sharing the details of the situa...   \n",
       "2  When you want to initialize the classification...   \n",
       "\n",
       "                                          response_b  \n",
       "0  You still have three oranges. Eating an orange...  \n",
       "1  Mr Reddy and Ms Blue both have valid points in...  \n",
       "2  To initialize the classification head when per...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "# concatenate strings in list\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)\n",
    "\n",
    "display(test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d8e46",
   "metadata": {
    "papermill": {
     "duration": 0.012863,
     "end_time": "2024-07-04T14:53:31.354381",
     "exception": false,
     "start_time": "2024-07-04T14:53:31.341518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70488e49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:53:31.382343Z",
     "iopub.status.busy": "2024-07-04T14:53:31.381919Z",
     "iopub.status.idle": "2024-07-04T14:53:31.392466Z",
     "shell.execute_reply": "2024-07-04T14:53:31.391344Z"
    },
    "papermill": {
     "duration": 0.02735,
     "end_time": "2024-07-04T14:53:31.395048",
     "exception": false,
     "start_time": "2024-07-04T14:53:31.367698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(\n",
    "    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n",
    "):\n",
    "    prompt = [\"User prompt: \" + p for p in prompt]\n",
    "    response_a = [\"\\n\\nModel A :\\n\" + r_a for r_a in response_a]\n",
    "    response_b = [\"\\n\\n--------\\n\\nModel B:\\n\" + r_b for r_b in response_b]\n",
    "    if spread_max_length:\n",
    "        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        attention_mask = [[1]* len(i) for i in input_ids]\n",
    "    else:\n",
    "        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)\n",
    "        input_ids = tokenized.input_ids\n",
    "        attention_mask = tokenized.attention_mask\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ac7d626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:53:31.425629Z",
     "iopub.status.busy": "2024-07-04T14:53:31.425158Z",
     "iopub.status.idle": "2024-07-04T14:53:32.030021Z",
     "shell.execute_reply": "2024-07-04T14:53:32.028619Z"
    },
    "papermill": {
     "duration": 0.623187,
     "end_time": "2024-07-04T14:53:32.032446",
     "exception": false,
     "start_time": "2024-07-04T14:53:31.409259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 432 ms, sys: 83.1 ms, total: 515 ms\n",
      "Wall time: 596 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/lmsys-model/tokenizer')\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"id\"] = test[\"id\"]\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
    "\n",
    "aug_data = pd.DataFrame()\n",
    "aug_data[\"id\"] = test[\"id\"]\n",
    "# swap response_a & response_b\n",
    "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01862254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:53:32.062522Z",
     "iopub.status.busy": "2024-07-04T14:53:32.062087Z",
     "iopub.status.idle": "2024-07-04T14:53:32.069829Z",
     "shell.execute_reply": "2024-07-04T14:53:32.068597Z"
    },
    "papermill": {
     "duration": 0.025986,
     "end_time": "2024-07-04T14:53:32.072844",
     "exception": false,
     "start_time": "2024-07-04T14:53:32.046858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User prompt: I have three oranges today, I ate an orange yesterday. How many oranges do I have?\n",
      "\n",
      "Model A :\n",
      "You have two oranges today.\n",
      "\n",
      "--------\n",
      "\n",
      "Model B:\n",
      "You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(data[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc5cf3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:53:32.102157Z",
     "iopub.status.busy": "2024-07-04T14:53:32.101465Z",
     "iopub.status.idle": "2024-07-04T14:53:32.108097Z",
     "shell.execute_reply": "2024-07-04T14:53:32.107122Z"
    },
    "papermill": {
     "duration": 0.024325,
     "end_time": "2024-07-04T14:53:32.111180",
     "exception": false,
     "start_time": "2024-07-04T14:53:32.086855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User prompt: I have three oranges today, I ate an orange yesterday. How many oranges do I have?\n",
      "\n",
      "Model A :\n",
      "You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.\n",
      "\n",
      "--------\n",
      "\n",
      "Model B:\n",
      "You have two oranges today.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(aug_data[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21354584",
   "metadata": {
    "papermill": {
     "duration": 0.012988,
     "end_time": "2024-07-04T14:53:32.137730",
     "exception": false,
     "start_time": "2024-07-04T14:53:32.124742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load model \n",
    "We load 1 model on each gpu.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3fa4a69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:53:32.166285Z",
     "iopub.status.busy": "2024-07-04T14:53:32.165890Z",
     "iopub.status.idle": "2024-07-04T14:55:23.809205Z",
     "shell.execute_reply": "2024-07-04T14:55:23.808227Z"
    },
    "papermill": {
     "duration": 111.660345,
     "end_time": "2024-07-04T14:55:23.811369",
     "exception": false,
     "start_time": "2024-07-04T14:53:32.151024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5128b4dd735f4cccb4a4d046858d5bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/llama-3/transformers/8b-chat-hf/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6ebbc02fef40119b4e999d8561ee5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/llama-3/transformers/8b-chat-hf/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BitsAndBytes configuration\n",
    "bnb_config =  BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=torch.float16,\n",
    "    bnb_8bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "# Load base model on GPU 0\n",
    "device_0 = torch.device('cuda:0')\n",
    "base_model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    cfg.model_name,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:0')\n",
    "base_model_0.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Load base model on GPU 1\n",
    "device_1 = torch.device('cuda:1')\n",
    "base_model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    cfg.model_name,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:1')\n",
    "base_model_1.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b871ac",
   "metadata": {
    "papermill": {
     "duration": 0.012056,
     "end_time": "2024-07-04T14:55:23.835922",
     "exception": false,
     "start_time": "2024-07-04T14:55:23.823866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca60a645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:55:23.861444Z",
     "iopub.status.busy": "2024-07-04T14:55:23.861170Z",
     "iopub.status.idle": "2024-07-04T14:55:23.865919Z",
     "shell.execute_reply": "2024-07-04T14:55:23.865135Z"
    },
    "papermill": {
     "duration": 0.019602,
     "end_time": "2024-07-04T14:55:23.867868",
     "exception": false,
     "start_time": "2024-07-04T14:55:23.848266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.10,\n",
    "    bias='none',\n",
    "    inference_mode=True,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=['o_proj', 'v_proj']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c555e473",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:55:23.894147Z",
     "iopub.status.busy": "2024-07-04T14:55:23.893816Z",
     "iopub.status.idle": "2024-07-04T14:55:37.219696Z",
     "shell.execute_reply": "2024-07-04T14:55:37.218609Z"
    },
    "papermill": {
     "duration": 13.341701,
     "end_time": "2024-07-04T14:55:37.221659",
     "exception": false,
     "start_time": "2024-07-04T14:55:23.879958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForSequenceClassification(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "              (k_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): Linear8bitLt(\n",
       "                in_features=4096, out_features=1024, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear8bitLt(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear8bitLt(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=4096, out_features=3, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=3, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get peft\n",
    "model_0 = get_peft_model(base_model_0, peft_config).to(device_0) \n",
    "# Load weights\n",
    "model_0.load_state_dict(torch.load(cfg.weights_path), strict=False)\n",
    "model_0.eval()\n",
    "\n",
    "model_1 = get_peft_model(base_model_1, peft_config).to(device_1)\n",
    "model_1.load_state_dict(torch.load(cfg.weights_path), strict=False)\n",
    "model_1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea85490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:55:37.248630Z",
     "iopub.status.busy": "2024-07-04T14:55:37.247905Z",
     "iopub.status.idle": "2024-07-04T14:55:37.260683Z",
     "shell.execute_reply": "2024-07-04T14:55:37.259623Z"
    },
    "papermill": {
     "duration": 0.028543,
     "end_time": "2024-07-04T14:55:37.262867",
     "exception": false,
     "start_time": "2024-07-04T14:55:37.234324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 24,576 || all params: 7,511,764,992 || trainable%: 0.00032716678471934814\n",
      "trainable params: 24,576 || all params: 7,511,764,992 || trainable%: 0.00032716678471934814\n"
     ]
    }
   ],
   "source": [
    "# Trainable Parameters\n",
    "model_0.print_trainable_parameters()\n",
    "model_1.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869bd7c",
   "metadata": {
    "papermill": {
     "duration": 0.013033,
     "end_time": "2024-07-04T14:55:37.289766",
     "exception": false,
     "start_time": "2024-07-04T14:55:37.276733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15a4a7ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:55:37.316487Z",
     "iopub.status.busy": "2024-07-04T14:55:37.315676Z",
     "iopub.status.idle": "2024-07-04T14:55:37.325046Z",
     "shell.execute_reply": "2024-07-04T14:55:37.324178Z"
    },
    "papermill": {
     "duration": 0.024851,
     "end_time": "2024-07-04T14:55:37.326922",
     "exception": false,
     "start_time": "2024-07-04T14:55:37.302071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "@torch.cuda.amp.autocast()\n",
    "def inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n",
    "    a_win, b_win, tie = [], [], []\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        tmp = df.iloc[start_idx:end_idx]\n",
    "        input_ids = tmp[\"input_ids\"].to_list()\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()\n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        outputs = model(**inputs.to(device))\n",
    "        proba = outputs.logits.softmax(-1).cpu()\n",
    "        \n",
    "        a_win.extend(proba[:, 0].tolist())\n",
    "        b_win.extend(proba[:, 1].tolist())\n",
    "        tie.extend(proba[:, 2].tolist())\n",
    "    \n",
    "    df[\"winner_model_a\"] = a_win\n",
    "    df[\"winner_model_b\"] = b_win\n",
    "    df[\"winner_tie\"] = tie\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86fd9a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:55:37.352844Z",
     "iopub.status.busy": "2024-07-04T14:55:37.352524Z",
     "iopub.status.idle": "2024-07-04T14:55:40.476521Z",
     "shell.execute_reply": "2024-07-04T14:55:40.475532Z"
    },
    "papermill": {
     "duration": 3.13935,
     "end_time": "2024-07-04T14:55:40.478633",
     "exception": false,
     "start_time": "2024-07-04T14:55:37.339283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 3.117558002471924\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "# sort by input length to fully leverage dynaminc padding\n",
    "data = data.sort_values(\"length\", ascending=False)\n",
    "# the total #tokens in sub_1 and sub_2 should be more or less the same\n",
    "sub_1 = data.iloc[0::2].copy()\n",
    "sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "result_df = pd.concat(list(results), axis=0)\n",
    "proba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values\n",
    "\n",
    "print(f\"elapsed time: {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7e8f07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:55:40.505992Z",
     "iopub.status.busy": "2024-07-04T14:55:40.505701Z",
     "iopub.status.idle": "2024-07-04T14:55:40.512991Z",
     "shell.execute_reply": "2024-07-04T14:55:40.512180Z"
    },
    "papermill": {
     "duration": 0.023358,
     "end_time": "2024-07-04T14:55:40.515371",
     "exception": false,
     "start_time": "2024-07-04T14:55:40.492013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.0002002716064453125\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "if cfg.tta:\n",
    "    data = aug_data.sort_values(\"length\", ascending=False)  # sort by input length to boost speed\n",
    "    sub_1 = data.iloc[0::2].copy()\n",
    "    sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "    tta_result_df = pd.concat(list(results), axis=0)\n",
    "    # recall TTA's order is flipped\n",
    "    tta_proba = tta_result_df[[\"winner_model_b\", \"winner_model_a\", \"winner_tie\"]].values \n",
    "    # average original result and TTA result.\n",
    "    proba = (proba + tta_proba) / 2\n",
    "\n",
    "print(f\"elapsed time: {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71c6ecda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:55:40.543258Z",
     "iopub.status.busy": "2024-07-04T14:55:40.542991Z",
     "iopub.status.idle": "2024-07-04T14:55:40.560088Z",
     "shell.execute_reply": "2024-07-04T14:55:40.559086Z"
    },
    "papermill": {
     "duration": 0.033031,
     "end_time": "2024-07-04T14:55:40.562081",
     "exception": false,
     "start_time": "2024-07-04T14:55:40.529050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.209280</td>\n",
       "      <td>0.463401</td>\n",
       "      <td>0.327319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.656575</td>\n",
       "      <td>0.236869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.349609</td>\n",
       "      <td>0.367821</td>\n",
       "      <td>0.282570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "2  1233961        0.209280        0.463401    0.327319\n",
       "0   136060        0.106557        0.656575    0.236869\n",
       "1   211333        0.349609        0.367821    0.282570"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]\n",
    "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]\n",
    "result_df.loc[:, \"winner_tie\"] = proba[:, 2]\n",
    "submission_df = result_df[[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "display(submission_df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5034873,
     "sourceId": 8449074,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 148861315,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 212.250463,
   "end_time": "2024-07-04T14:55:43.529889",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-04T14:52:11.279426",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "144acaa8fbda474d94b713eb42c9846c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_beb6963a1f0c4f04b2ced833287ea0b4",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_58e249a59ead475290cfbf8bf0eb9a53",
       "value": 4
      }
     },
     "2d03fc727f8545708cf1e32213ce18b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bca1da710717470197e9a718817421e5",
       "placeholder": "​",
       "style": "IPY_MODEL_93e9e5e2d90740f58d07f452f74826b3",
       "value": " 4/4 [00:12&lt;00:00,  2.67s/it]"
      }
     },
     "3383719e39fe4c68a7a1af007cebb9c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3b541952c31e484da05b3b2b6cdcf5dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_94d1abfc01c0429496be5fc72e1ad1a9",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3383719e39fe4c68a7a1af007cebb9c5",
       "value": 4
      }
     },
     "402922230d5b472fa2742817206c650e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5128b4dd735f4cccb4a4d046858d5bd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7524b2eec5fb401f830e8290f3e0ce31",
        "IPY_MODEL_144acaa8fbda474d94b713eb42c9846c",
        "IPY_MODEL_c229f4670e264e0691867fc27affb6af"
       ],
       "layout": "IPY_MODEL_534717fcbc5f4553a1eee6849a5cb2c4"
      }
     },
     "534717fcbc5f4553a1eee6849a5cb2c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58e249a59ead475290cfbf8bf0eb9a53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7524b2eec5fb401f830e8290f3e0ce31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_402922230d5b472fa2742817206c650e",
       "placeholder": "​",
       "style": "IPY_MODEL_760ed7f58abf4671a05f893eb9d4cee1",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "760ed7f58abf4671a05f893eb9d4cee1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8dfa1f73b9b945e48b936d58f3e942dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91932f86e17840158de3833cdd90fef1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8dfa1f73b9b945e48b936d58f3e942dc",
       "placeholder": "​",
       "style": "IPY_MODEL_e448a5b6cc794dc0966db09b6ad6310e",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "93e9e5e2d90740f58d07f452f74826b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "94d1abfc01c0429496be5fc72e1ad1a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f6ebbc02fef40119b4e999d8561ee5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_91932f86e17840158de3833cdd90fef1",
        "IPY_MODEL_3b541952c31e484da05b3b2b6cdcf5dd",
        "IPY_MODEL_2d03fc727f8545708cf1e32213ce18b4"
       ],
       "layout": "IPY_MODEL_d1945c7881254792b8f288b0b06b0078"
      }
     },
     "bca1da710717470197e9a718817421e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "beb6963a1f0c4f04b2ced833287ea0b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c229f4670e264e0691867fc27affb6af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fd68d7196c304c47a29c9ddda11ca6b7",
       "placeholder": "​",
       "style": "IPY_MODEL_dc98d3b46c014ae79f86f376e4f38eb0",
       "value": " 4/4 [01:37&lt;00:00, 19.78s/it]"
      }
     },
     "d1945c7881254792b8f288b0b06b0078": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc98d3b46c014ae79f86f376e4f38eb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e448a5b6cc794dc0966db09b6ad6310e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fd68d7196c304c47a29c9ddda11ca6b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
